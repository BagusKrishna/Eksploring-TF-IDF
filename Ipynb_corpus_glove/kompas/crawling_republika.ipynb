{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c41441a9",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "2b13fc14",
      "metadata": {},
      "source": [
        "## CRAWL dari REPUBLIKA"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "05067ebc",
      "metadata": {},
      "source": [
        "### Def untuk crawling dari Portal REPUBLIKA\n",
        "Note : \n",
        "- ganti User-Agent pada headers -> ke user agent browser sendiri"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e15856fb",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import time\n",
        "import csv\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from urllib.parse import quote # Penting untuk keyword dengan spasi\n",
        "\n",
        "def republika_scraper(keywords, n_berita):\n",
        "    # Menggunakan session untuk mengelola koneksi dan header\n",
        "    session = requests.Session()\n",
        "    session.headers.update({\n",
        "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/118.0.0.0 Safari/537.36',\n",
        "        'Referer': 'https://republika.co.id/'\n",
        "    })\n",
        "\n",
        "    save_dir = r\"/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/corpus/republika\"\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # === PERUBAHAN UTAMA: Loop untuk setiap keyword ===\n",
        "    for keyword in keywords:\n",
        "        print(f\"\\nüöÄ Mulai scraping untuk kata kunci: '{keyword}'\")\n",
        "        \n",
        "        data_republika = []\n",
        "        page = 1\n",
        "\n",
        "        while len(data_republika) < n_berita:\n",
        "            # Menggunakan API endpoint yang benar untuk hasil yang reliable\n",
        "            api_url = f'https://republika.co.id/search/v3/q?q={quote(keyword)}&sortby=time&page={page}'\n",
        "            \n",
        "            try:\n",
        "                print(f\"üîÑ Mengambil data dari API halaman {page} untuk '{keyword}'...\")\n",
        "                response = session.get(api_url, timeout=15)\n",
        "                response.raise_for_status() # Cek jika ada error HTTP\n",
        "                search_results = response.json()\n",
        "                articles = search_results.get('articles', [])\n",
        "\n",
        "            except requests.exceptions.RequestException as e:\n",
        "                print(f\"‚ùå Gagal mengakses API: {e}\")\n",
        "                break\n",
        "            except requests.exceptions.JSONDecodeError:\n",
        "                print(f\"‚ùå Gagal parsing JSON. Kemungkinan diblokir atau halaman kosong.\")\n",
        "                break\n",
        "\n",
        "            if not articles:\n",
        "                print(\"‚úÖ Tidak ada artikel lagi dari API.\")\n",
        "                break\n",
        "\n",
        "            for article_data in articles:\n",
        "                try:\n",
        "                    url = article_data.get('url')\n",
        "                    judul = article_data.get('title', 'Tanpa Judul')\n",
        "                    \n",
        "                    if not url:\n",
        "                        continue\n",
        "\n",
        "                    # Mengambil halaman detail artikel\n",
        "                    detail_res = session.get(url, timeout=10)\n",
        "                    detail_soup = BeautifulSoup(detail_res.content, 'html.parser')\n",
        "                    \n",
        "                    # Menggunakan class selector yang benar untuk konten berita\n",
        "                    konten = detail_soup.find('div', class_='post-content')\n",
        "                    \n",
        "                    if konten:\n",
        "                        # Membersihkan teks dari \"Baca Juga\"\n",
        "                        for tag in konten.find_all(['strong', 'em'], text=lambda t: t and 'baca juga' in t.lower()):\n",
        "                            tag.find_parent('p').decompose()\n",
        "                        isi = konten.get_text(separator=' ', strip=True)\n",
        "                    else:\n",
        "                        isi = \"Tidak ditemukan isi berita\"\n",
        "\n",
        "                    if len(isi) > 50: # Menaikkan batas minimum panjang berita\n",
        "                        data_republika.append({\n",
        "                            'judul': judul,\n",
        "                            'berita': isi,\n",
        "                            'url': url,\n",
        "                        })\n",
        "                        print(f\"    [{len(data_republika)}] Berhasil mengambil: {judul}\")\n",
        "\n",
        "                    if len(data_republika) >= n_berita:\n",
        "                        break\n",
        "                    \n",
        "                    time.sleep(0.5) # Delay antar request detail\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"    ‚ö†Ô∏è Error saat memproses artikel {url}: {e}\")\n",
        "                    continue\n",
        "            \n",
        "            page += 1\n",
        "            if len(data_republika) >= n_berita:\n",
        "                break\n",
        "\n",
        "        # Logika penyimpanan file berada di dalam loop keyword\n",
        "        if data_republika:\n",
        "            filename = os.path.join(save_dir, f\"republika_news_{keyword.lower().replace(' ','_')}_{time.strftime('%Y%m%d')}.csv\")\n",
        "            with open(filename, \"w\", newline=\"\", encoding=\"utf-8-sig\") as f:\n",
        "                writer = csv.DictWriter(f, fieldnames=[\"judul\", \"berita\", \"url\"])\n",
        "                writer.writeheader()\n",
        "                writer.writerows(data_republika)\n",
        "            print(f\"\\n‚úÖ Selesai! {len(data_republika)} artikel '{keyword}' disimpan ke {filename}\")\n",
        "        else:\n",
        "            print(f\"‚ùå Tidak ada data yang ditemukan untuk '{keyword}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "212eba74",
      "metadata": {},
      "outputs": [],
      "source": [
        "keywords = [\n",
        "    \"BI rate\",\n",
        "    \"Pertumbuhan ekonomi\",\n",
        "    \"Inflasi\",\n",
        "    \"Bank Indonesia\",\n",
        "    \"Perbankan digital\",\n",
        "    \"IHSG\",\n",
        "    \"Pelemahan Rupiah\",\n",
        "    \"Investasi\",\n",
        "    \"Ekonomi Indonesia\",\n",
        "    \"Danantara\",\n",
        "    \"OJK\",\n",
        "    \"Reksadana\",\n",
        "    \"Bursa Efek Indonesia\",\n",
        "    \"BEI\",\n",
        "    \"Ekonomi digital\"\n",
        "]\n",
        "\n",
        "republika_scraper(keywords, n_berita=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5f45f46",
      "metadata": {},
      "outputs": [],
      "source": [
        "republika_scraper(keyword=\"IHSG\", n_berita=300)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
