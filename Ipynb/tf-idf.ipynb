{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c113c08d",
   "metadata": {},
   "source": [
    "# TF-IDF Pembobotan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a0165",
   "metadata": {},
   "source": [
    "## Import Library & Dataset Hasil Prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e07f74a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3e845f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data latih berhasil dimuat: 11413 baris.\n",
      "Data uji berhasil dimuat: 4892 baris.\n",
      "Rasio split terdeteksi: 7030\n"
     ]
    }
   ],
   "source": [
    "def load_split_data(split_dir, train_filename, test_filename):\n",
    "    \"\"\"Memuat dataset train dan test, dan mendeteksi rasio split dari nama file.\"\"\"\n",
    "    \n",
    "    train_path = os.path.join(split_dir, train_filename)\n",
    "    test_path = os.path.join(split_dir, test_filename)\n",
    "    \n",
    "    try:\n",
    "        train_df = pd.read_csv(train_path)\n",
    "        test_df = pd.read_csv(test_path)\n",
    "        \n",
    "        # Ekstrak angka dari nama file untuk mendapatkan rasio (contoh: '8020')\n",
    "        split_ratio_str = re.search(r'(\\d+)', train_filename).group(1)\n",
    "        \n",
    "        print(f\"Data latih berhasil dimuat: {train_df.shape[0]} baris.\")\n",
    "        print(f\"Data uji berhasil dimuat: {test_df.shape[0]} baris.\")\n",
    "        print(f\"Rasio split terdeteksi: {split_ratio_str}\")\n",
    "        \n",
    "        return train_df, test_df, split_ratio_str\n",
    "        \n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"Error: Salah satu file tidak ditemukan. {e}\")\n",
    "        return None, None, None\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi (CUSTOM)---\n",
    "SPLIT_DATA_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\split_data'\n",
    "TRAIN_FILENAME = 'train7030.csv'  \n",
    "TEST_FILENAME = 'test7030.csv'\n",
    "\n",
    "train_df, test_df, split_ratio = load_split_data(SPLIT_DATA_DIR, TRAIN_FILENAME, TEST_FILENAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b135",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4fa23af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai ekstraksi fitur TF-IDF Unigram...\n",
      "Ukuran matriks train: (11413, 16020)\n",
      "Ukuran matriks test: (4892, 16020)\n",
      "Hasil ekstraksi fitur Unigram berhasil disimpan di: E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts\\unigram_7030\n"
     ]
    }
   ],
   "source": [
    "def extract_tfidf_unigram(train_df, test_df, output_dir):\n",
    "    \"\"\"Melakukan ekstraksi fitur TF-IDF (unigram) dan menyimpan hasilnya.\"\"\"\n",
    "    \n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    train_texts = train_df['clean_text'].fillna(\"\").astype(str)\n",
    "    test_texts = test_df['clean_text'].fillna(\"\").astype(str)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 1),\n",
    "        max_features=20000,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    \n",
    "    print(\"Memulai ekstraksi fitur TF-IDF Unigram...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"Ukuran matriks train: {X_train.shape}\")\n",
    "    print(f\"Ukuran matriks test: {X_test.shape}\")\n",
    "\n",
    "    pickle.dump(vectorizer, open(os.path.join(output_dir, \"vectorizer_unigram.pkl\"), \"wb\"))\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_train_unigram.npz\"), X_train)\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_test_unigram.npz\"), X_test)\n",
    "    \n",
    "    print(f\"Hasil ekstraksi fitur Unigram berhasil disimpan di: {output_dir}\")\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi ---\n",
    "TFIDF_ARTIFACTS_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts'\n",
    "\n",
    "dynamic_folder_name = f'unigram_{split_ratio}'\n",
    "UNIGRAM_OUTPUT_DIR = os.path.join(TFIDF_ARTIFACTS_DIR, dynamic_folder_name)\n",
    "    \n",
    "extract_tfidf_unigram(train_df, test_df, UNIGRAM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151e368",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "36af7d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai ekstraksi fitur TF-IDF Bigram...\n",
      "Ukuran matriks train: (11413, 20000)\n",
      "Ukuran matriks test: (4892, 20000)\n",
      "Hasil ekstraksi fitur Bigram berhasil disimpan di: E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts\\bigram_7030\n"
     ]
    }
   ],
   "source": [
    "def extract_tfidf_bigram(train_df, test_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_texts = train_df['clean_text'].fillna(\"\").astype(str)\n",
    "    test_texts = test_df['clean_text'].fillna(\"\").astype(str)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(2, 2),\n",
    "        max_features=20000,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    \n",
    "    print(\"Memulai ekstraksi fitur TF-IDF Bigram...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"Ukuran matriks train: {X_train.shape}\")\n",
    "    print(f\"Ukuran matriks test: {X_test.shape}\")\n",
    "\n",
    "    pickle.dump(vectorizer, open(os.path.join(output_dir, \"vectorizer_bigram.pkl\"), \"wb\"))\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_train_bigram.npz\"), X_train)\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_test_bigram.npz\"), X_test)\n",
    "    \n",
    "    print(f\"Hasil ekstraksi fitur Bigram berhasil disimpan di: {output_dir}\")\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi ---\n",
    "TFIDF_ARTIFACTS_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts'\n",
    "BIGRAM_OUTPUT_DIR = os.path.join(TFIDF_ARTIFACTS_DIR, f'bigram_{split_ratio}')\n",
    "extract_tfidf_bigram(train_df, test_df, BIGRAM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba422e",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6f44d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai ekstraksi fitur TF-IDF Trigram...\n",
      "Ukuran matriks train: (11413, 20000)\n",
      "Ukuran matriks test: (4892, 20000)\n",
      "Hasil ekstraksi fitur Trigram berhasil disimpan di: E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts\\trigram_7030\n"
     ]
    }
   ],
   "source": [
    "def extract_tfidf_trigram(train_df, test_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_texts = train_df['clean_text'].fillna(\"\").astype(str)\n",
    "    test_texts = test_df['clean_text'].fillna(\"\").astype(str)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(3, 3),\n",
    "        max_features=20000,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    \n",
    "    print(\"Memulai ekstraksi fitur TF-IDF Trigram...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"Ukuran matriks train: {X_train.shape}\")\n",
    "    print(f\"Ukuran matriks test: {X_test.shape}\")\n",
    "\n",
    "    pickle.dump(vectorizer, open(os.path.join(output_dir, \"vectorizer_trigram.pkl\"), \"wb\"))\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_train_trigram.npz\"), X_train)\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_test_trigram.npz\"), X_test)\n",
    "    \n",
    "    print(f\"Hasil ekstraksi fitur Trigram berhasil disimpan di: {output_dir}\")\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi ---\n",
    "TFIDF_ARTIFACTS_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts'\n",
    "TRIGRAM_OUTPUT_DIR = os.path.join(TFIDF_ARTIFACTS_DIR, f'trigram_{split_ratio}')\n",
    "extract_tfidf_trigram(train_df, test_df, TRIGRAM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e0e2d",
   "metadata": {},
   "source": [
    "## Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "34f38b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai ekstraksi fitur TF-IDF Unigram + Bigram...\n",
      "Ukuran matriks train: (11413, 20000)\n",
      "Ukuran matriks test: (4892, 20000)\n",
      "Hasil ekstraksi fitur Unigram + Bigram berhasil disimpan di: E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts\\uni_bigram_7030\n"
     ]
    }
   ],
   "source": [
    "def extract_tfidf_uni_bigram(train_df, test_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_texts = train_df['clean_text'].fillna(\"\").astype(str)\n",
    "    test_texts = test_df['clean_text'].fillna(\"\").astype(str)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 2),\n",
    "        max_features=20000,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    \n",
    "    print(\"Memulai ekstraksi fitur TF-IDF Unigram + Bigram...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"Ukuran matriks train: {X_train.shape}\")\n",
    "    print(f\"Ukuran matriks test: {X_test.shape}\")\n",
    "\n",
    "    pickle.dump(vectorizer, open(os.path.join(output_dir, \"vectorizer_uni_bigram.pkl\"), \"wb\"))\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_train_uni_bigram.npz\"), X_train)\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_test_uni_bigram.npz\"), X_test)\n",
    "    \n",
    "    print(f\"Hasil ekstraksi fitur Unigram + Bigram berhasil disimpan di: {output_dir}\")\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi ---\n",
    "TFIDF_ARTIFACTS_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts'\n",
    "UNI_BIGRAM_OUTPUT_DIR = os.path.join(TFIDF_ARTIFACTS_DIR, f'uni_bigram_{split_ratio}')\n",
    "extract_tfidf_uni_bigram(train_df, test_df, UNI_BIGRAM_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3ee0c",
   "metadata": {},
   "source": [
    "## Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c399d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNIGRAM + BIGRAM + TRIGRAM ===\n",
      "Shape: (16519, 297556)\n"
     ]
    }
   ],
   "source": [
    "def extract_tfidf_uni_bi_trigram(train_df, test_df, output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    train_texts = train_df['clean_text'].fillna(\"\").astype(str)\n",
    "    test_texts = test_df['clean_text'].fillna(\"\").astype(str)\n",
    "    \n",
    "    vectorizer = TfidfVectorizer(\n",
    "        ngram_range=(1, 3),\n",
    "        max_features=20000,\n",
    "        token_pattern=r\"(?u)\\b\\w\\w+\\b\"\n",
    "    )\n",
    "    \n",
    "    print(\"Memulai ekstraksi fitur TF-IDF Unigram + Bigram + Trigram...\")\n",
    "    X_train = vectorizer.fit_transform(train_texts)\n",
    "    X_test = vectorizer.transform(test_texts)\n",
    "    \n",
    "    print(f\"Ukuran matriks train: {X_train.shape}\")\n",
    "    print(f\"Ukuran matriks test: {X_test.shape}\")\n",
    "\n",
    "    pickle.dump(vectorizer, open(os.path.join(output_dir, \"vectorizer_uni_bi_trigram.pkl\"), \"wb\"))\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_train_uni_bi_trigram.npz\"), X_train)\n",
    "    sparse.save_npz(os.path.join(output_dir, \"X_test_uni_bi_trigram.npz\"), X_test)\n",
    "    \n",
    "    print(f\"Hasil ekstraksi fitur Unigram + Bigram + Trigram berhasil disimpan di: {output_dir}\")\n",
    "\n",
    "# --- Konfigurasi dan Eksekusi ---\n",
    "TFIDF_ARTIFACTS_DIR = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\tfidf_artifacts'\n",
    "UNI_BI_TRIGRAM_OUTPUT_DIR = os.path.join(TFIDF_ARTIFACTS_DIR, f'uni_bi_trigram_{split_ratio}')\n",
    "extract_tfidf_uni_bi_trigram(train_df, test_df, UNI_BI_TRIGRAM_OUTPUT_DIR)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
