{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c113c08d",
   "metadata": {},
   "source": [
    "# TF-IDF Pembobotan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740a0165",
   "metadata": {},
   "source": [
    "## Import Library & Dataset Hasil Prepro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e845f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded: 16305 rows\n"
     ]
    }
   ],
   "source": [
    "# ===== TF-IDF Experiment Setup =====\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy import sparse\n",
    "import pickle\n",
    "\n",
    "# Load dataframe hasil preprocessing\n",
    "cleaned_text_path = r'E:\\$7th\\TA\\Eksploring_TF-IDF\\DATA\\Cleaned_Text.csv'\n",
    "df = pd.read_csv(cleaned_text_path)\n",
    "texts = df[\"clean_text\"].fillna(\"\").astype(str)\n",
    "texts = texts[texts.str.strip() != \"\"]\n",
    "\n",
    "# Output directory\n",
    "out_dir = os.path.join(os.path.dirname(cleaned_text_path), 'tfidf_artifacts')\n",
    "os.makedirs(out_dir, exist_ok=True)\n",
    "\n",
    "print(f\"Dataset loaded: {len(texts)} rows\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c5b135",
   "metadata": {},
   "source": [
    "## Unigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fa23af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNIGRAM ===\n",
      "Shape: (16519, 19406)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== UNIGRAM ===\")\n",
    "vectorizer_uni = TfidfVectorizer(ngram_range=(1,1))\n",
    "\n",
    "X_uni = vectorizer_uni.fit_transform(texts)\n",
    "print(\"Shape:\", X_uni.shape)\n",
    "\n",
    "pickle.dump(vectorizer_uni, open(os.path.join(out_dir, \"vectorizer_unigram.pkl\"), \"wb\"))\n",
    "sparse.save_npz(os.path.join(out_dir, \"matrix_unigram.npz\"), X_uni)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0151e368",
   "metadata": {},
   "source": [
    "## Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "36af7d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== BIGRAM ===\n",
      "Shape: (16519, 120467)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== BIGRAM ===\")\n",
    "vectorizer_bi = TfidfVectorizer(ngram_range=(2,2))\n",
    "\n",
    "X_bi = vectorizer_bi.fit_transform(texts)\n",
    "print(\"Shape:\", X_bi.shape)\n",
    "\n",
    "pickle.dump(vectorizer_bi, open(os.path.join(out_dir, \"vectorizer_bigram.pkl\"), \"wb\"))\n",
    "sparse.save_npz(os.path.join(out_dir, \"matrix_bigram.npz\"), X_bi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cba422e",
   "metadata": {},
   "source": [
    "## Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f44d7bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== TRIGRAM ===\n",
      "Shape: (16519, 157683)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== TRIGRAM ===\")\n",
    "vectorizer_tri = TfidfVectorizer(ngram_range=(3,3))\n",
    "\n",
    "X_tri = vectorizer_tri.fit_transform(texts)\n",
    "print(\"Shape:\", X_tri.shape)\n",
    "\n",
    "pickle.dump(vectorizer_tri, open(os.path.join(out_dir, \"vectorizer_trigram.pkl\"), \"wb\"))\n",
    "sparse.save_npz(os.path.join(out_dir, \"matrix_trigram.npz\"), X_tri)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e0e2d",
   "metadata": {},
   "source": [
    "## Unigram + Bigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "34f38b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNIGRAM + BIGRAM ===\n",
      "Shape: (16519, 139873)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== UNIGRAM + BIGRAM ===\")\n",
    "vectorizer_unibi = TfidfVectorizer(ngram_range=(1,2))\n",
    "\n",
    "X_unibi = vectorizer_unibi.fit_transform(texts)\n",
    "print(\"Shape:\", X_unibi.shape)\n",
    "\n",
    "pickle.dump(vectorizer_unibi, open(os.path.join(out_dir, \"vectorizer_unibigram.pkl\"), \"wb\"))\n",
    "sparse.save_npz(os.path.join(out_dir, \"matrix_unibigram.npz\"), X_unibi)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa3ee0c",
   "metadata": {},
   "source": [
    "## Unigram + Bigram + Trigram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9c399d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== UNIGRAM + BIGRAM + TRIGRAM ===\n",
      "Shape: (16519, 297556)\n"
     ]
    }
   ],
   "source": [
    "print(\"=== UNIGRAM + BIGRAM + TRIGRAM ===\")\n",
    "vectorizer_all = TfidfVectorizer(ngram_range=(1,3))\n",
    "\n",
    "X_all = vectorizer_all.fit_transform(texts)\n",
    "print(\"Shape:\", X_all.shape)\n",
    "\n",
    "pickle.dump(vectorizer_all, open(os.path.join(out_dir, \"vectorizer_unibi_tri.pkl\"), \"wb\"))\n",
    "sparse.save_npz(os.path.join(out_dir, \"matrix_unibi_tri.npz\"), X_all)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
