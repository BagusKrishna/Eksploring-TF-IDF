{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "09d2fe29",
      "metadata": {},
      "source": [
        "## Feature Engineering untuk concat feature"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9226d875",
      "metadata": {},
      "source": [
        "### Import Library"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59722edd",
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pickle\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96acc8b1",
      "metadata": {},
      "source": [
        "### Load Dataset Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b0b7cd83",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data latih berhasil dimuat: 13044 baris.\n",
            "Data uji berhasil dimuat: 3261 baris.\n",
            "Rasio split terdeteksi: 8020\n"
          ]
        }
      ],
      "source": [
        "def load_split_data(split_dir, train_filename, test_filename):\n",
        "    \"\"\"Memuat dataset train dan test, dan mendeteksi rasio split dari nama file.\"\"\"\n",
        "    \n",
        "    train_path = os.path.join(split_dir, train_filename)\n",
        "    test_path = os.path.join(split_dir, test_filename)\n",
        "    \n",
        "    try:\n",
        "        train_df = pd.read_csv(train_path)\n",
        "        test_df = pd.read_csv(test_path)\n",
        "        \n",
        "        # Ekstrak angka dari nama file untuk mendapatkan rasio (contoh: '8020')\n",
        "        split_ratio_str = re.search(r'(/d+)', train_filename).group(1)\n",
        "        \n",
        "        print(f\"Data latih berhasil dimuat: {train_df.shape[0]} baris.\")\n",
        "        print(f\"Data uji berhasil dimuat: {test_df.shape[0]} baris.\")\n",
        "        print(f\"Rasio split terdeteksi: {split_ratio_str}\")\n",
        "        \n",
        "        return train_df, test_df, split_ratio_str\n",
        "        \n",
        "    except FileNotFoundError as e:\n",
        "        print(f\"Error: Salah satu file tidak ditemukan. {e}\")\n",
        "        return None, None, None\n",
        "\n",
        "# --- Konfigurasi dan Eksekusi (CUSTOM)---\n",
        "SPLIT_DATA_DIR = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/split_data'\n",
        "TRAIN_FILENAME = 'train8020.csv'  \n",
        "TEST_FILENAME = 'test8020.csv'\n",
        "\n",
        "train_df, test_df, split_ratio = load_split_data(SPLIT_DATA_DIR, TRAIN_FILENAME, TEST_FILENAME)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b03de710",
      "metadata": {},
      "source": [
        "### Select Feature "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "a7f10593",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Pemilihan fitur metadata berhasil untuk data train dan test.\n"
          ]
        }
      ],
      "source": [
        "def select_metadata_features(df, feature_list):\n",
        "    \"\"\"Memilih kolom fitur metadata yang relevan beserta labelnya.\"\"\"\n",
        "    \n",
        "    required_cols = feature_list + ['Label']\n",
        "    \n",
        "    if not all(col in df.columns for col in required_cols):\n",
        "        missing = set(required_cols) - set(df.columns)\n",
        "        print(f\"Error: Kolom berikut tidak ditemukan: {missing}\")\n",
        "        return None\n",
        "        \n",
        "    return df[required_cols]\n",
        "\n",
        "# --- Konfigurasi dan Eksekusi ---\n",
        "METADATA_FEATURES = [\n",
        "    'followers_count',\n",
        "    'verified_account',\n",
        "    'age_account',\n",
        "    'quote_count',\n",
        "    'reply_count',\n",
        "    'retweet_count',\n",
        "    'favorite_count',\n",
        "    'image_corelation'\n",
        "]\n",
        "\n",
        "if 'train_df' in locals():\n",
        "    train_metadata_df = select_metadata_features(train_df, METADATA_FEATURES)\n",
        "    test_metadata_df = select_metadata_features(test_df, METADATA_FEATURES)\n",
        "    \n",
        "    if train_metadata_df is not None:\n",
        "        print(\"Pemilihan fitur metadata berhasil untuk data train dan test.\")\n",
        "        # print(train_metadata_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c4c096be",
      "metadata": {},
      "source": [
        "### Scalling / Standarisasi (Numerik)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c26aee9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitur numerik berhasil di-scale.\n"
          ]
        }
      ],
      "source": [
        "def scale_features(train_df, test_df):\n",
        "    \"\"\"Melakukan standard scaling pada fitur numerik.\"\"\"\n",
        "    \n",
        "    # Pisahkan fitur (X) dari label (y)\n",
        "    X_train = train_df.drop('Label', axis=1)\n",
        "    y_train = train_df['Label']\n",
        "    X_test = test_df.drop('Label', axis=1)\n",
        "    y_test = test_df['Label']\n",
        "    \n",
        "    scaler = StandardScaler()\n",
        "    \n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "    \n",
        "    print(\"Fitur numerik berhasil di-scale.\")\n",
        "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
        "\n",
        "# --- Eksekusi ---\n",
        "if 'train_metadata_df' in locals():\n",
        "    X_train_scaled, X_test_scaled, y_train, y_test, scaler = scale_features(train_metadata_df, test_metadata_df)\n",
        "    # print(f\"Shape X_train_scaled: {X_train_scaled.shape}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11028fe8",
      "metadata": {},
      "source": [
        "### Save File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9face23b",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Semua artefak metadata berhasil disimpan di folder: E:/$7th/TA/Eksploring_TF-IDF/DATA/_feature_artifacts/metadata_8020\n"
          ]
        }
      ],
      "source": [
        "def save_metadata_artifacts(X_train_s, X_test_s, y_train_s, y_test_s, scaler_obj, output_dir):\n",
        "    \"\"\"Menyimpan fitur yang sudah diproses dan objek scaler.\"\"\"\n",
        "    \n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "    \n",
        "    # Simpan fitur yang sudah di-scale sebagai array NumPy (.npy)\n",
        "    np.save(os.path.join(output_dir, 'X_train_metadata.npy'), X_train_s)\n",
        "    np.save(os.path.join(output_dir, 'X_test_metadata.npy'), X_test_s)\n",
        "    \n",
        "    # Simpan objek scaler yang sudah dilatih (.pkl)\n",
        "    with open(os.path.join(output_dir, 'metadata_scaler.pkl'), 'wb') as f:\n",
        "        pickle.dump(scaler_obj, f)\n",
        "        \n",
        "    print(f\"Semua artefak metadata berhasil disimpan di folder: {output_dir}\")\n",
        "\n",
        "# --- Konfigurasi dan Eksekusi ---\n",
        "BASE_ARTIFACTS_DIR = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/_feature_artifacts'\n",
        "\n",
        "if 'X_train_scaled' in locals() and 'split_ratio' in locals():\n",
        "    dynamic_folder_name = f'metadata_{split_ratio}'\n",
        "    METADATA_OUTPUT_DIR = os.path.join(BASE_ARTIFACTS_DIR, dynamic_folder_name)\n",
        "    \n",
        "    save_metadata_artifacts(X_train_scaled, X_test_scaled, y_train, y_test, scaler, METADATA_OUTPUT_DIR)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}