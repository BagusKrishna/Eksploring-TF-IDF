{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "aeb22b8d",
      "metadata": {},
      "source": [
        "## Temp (Anything)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c972d2a0",
      "metadata": {},
      "source": [
        "### Checking Missing value/ Nan dari csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "5a954d86",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jumlah row kosong/NaN: 0\n",
            "Index yang kosong/NaN: []\n",
            "/nJumlah row setelah drop: 16305\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load file dengan index asli\n",
        "cleaned_text_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/Cleaned_Text.csv'\n",
        "df = pd.read_csv(cleaned_text_path, index_col=0)\n",
        "\n",
        "# Cari baris yang kosong/NaN\n",
        "mask_empty = df[\"clean_text\"].isna() | (df[\"clean_text\"].astype(str).str.strip() == \"\")\n",
        "empty_indices = df.index[mask_empty].tolist()\n",
        "\n",
        "print(f\"Jumlah row kosong/NaN: {len(empty_indices)}\")\n",
        "print(\"Index yang kosong/NaN:\", empty_indices)\n",
        "\n",
        "# Drop baris yang kosong\n",
        "df_cleaned = df[~mask_empty].copy()\n",
        "\n",
        "print(f\"/nJumlah row setelah drop: {len(df_cleaned)}\")\n",
        "\n",
        "# Simpan kembali (overwrite file lama atau simpan sebagai file baru)\n",
        "#output_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/Cleaned_Text.csv'\n",
        "#df_cleaned.to_csv(output_path, index=True)\n",
        "#print(f\"✅ File baru disimpan di: {output_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fdf8439",
      "metadata": {},
      "source": [
        "## Formatting Dataset csv Cleaned\n",
        "disini buat coba formatting kolom age_account, created_at, sama followers_count"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "263a5702",
      "metadata": {},
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58509f2f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading data from: E:/$7th/TA/Eksploring_TF-IDF/DATA/Cleaned_Text.csv\n",
            "Data loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "# Path file\n",
        "path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/Cleaned_Text.csv'\n",
        "print(f\"Loading data from: {path}\")\n",
        "df = pd.read_csv(path)\n",
        "print(\"Data loaded successfully.\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69ac0069",
      "metadata": {},
      "source": [
        "#### Cleaning created_at"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8de166ae",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "            created_at\n",
            "0  2025-01-02 14:32:02\n",
            "1  2025-02-25 10:00:56\n",
            "2  2025-02-28 08:56:27\n",
            "3  2025-03-20 13:07:10\n",
            "4  2025-02-01 14:11:09\n",
            "5  2025-04-08 14:55:24\n",
            "6  2025-03-02 06:07:20\n",
            "7  2025-04-18 03:14:37\n",
            "8  2025-02-05 08:14:33\n",
            "9  2025-04-05 12:57:37\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:/Users/LEGION/AppData/Local/Temp/ipykernel_25872/2009035211.py:3: UserWarning: The argument 'infer_datetime_format' is deprecated and will be removed in a future version. A strict version of it is now the default, see https://pandas.pydata.org/pdeps/0004-consistent-to-datetime-parsing.html. You can safely remove this argument.\n",
            "  df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True, utc=True)\n"
          ]
        }
      ],
      "source": [
        "def clean_created_at(df, col=\"created_at\"):\n",
        "    # coba parsing otomatis semua format\n",
        "    df[col] = pd.to_datetime(df[col], errors=\"coerce\", infer_datetime_format=True, utc=True)\n",
        "    # hilangkan timezone biar rapi\n",
        "    df[col] = df[col].dt.tz_localize(None)\n",
        "    # format ulang\n",
        "    df[col] = df[col].dt.strftime(\"%Y-%m-%d %H:%M:%S\")\n",
        "    return df\n",
        "\n",
        "df = clean_created_at(df)\n",
        "print(df[[\"created_at\"]].head(10))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7452d6db",
      "metadata": {},
      "source": [
        "#### Cleaning age_account"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "9f046caf",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   age_account\n",
            "0           80\n",
            "1          140\n",
            "2           20\n",
            "3          165\n",
            "4          116\n"
          ]
        }
      ],
      "source": [
        "def convert_age_to_months(text):\n",
        "    if pd.isna(text):\n",
        "        return None\n",
        "    match = re.findall(r'(/d+)', str(text))\n",
        "    if not match:\n",
        "        return None\n",
        "    tahun = int(match[0]) if len(match) > 0 else 0\n",
        "    bulan = int(match[1]) if len(match) > 1 else 0\n",
        "    return tahun * 12 + bulan\n",
        "\n",
        "def clean_age_account(df, col=\"age_account\"):\n",
        "    df[col] = df[col].apply(convert_age_to_months)\n",
        "    return df\n",
        "\n",
        "df = clean_age_account(df)\n",
        "print(df[[\"age_account\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2de65d28",
      "metadata": {},
      "source": [
        "#### Cleaning followers_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "f778b1a7",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   followers_count\n",
            "0            91600\n",
            "1              695\n",
            "2              133\n",
            "3              353\n",
            "4           128000\n"
          ]
        }
      ],
      "source": [
        "def clean_followers_count(df, col=\"followers_count\"):\n",
        "    df[col] = df[col].fillna(0).astype(int)\n",
        "    return df\n",
        "\n",
        "df = clean_followers_count(df)\n",
        "print(df[[\"followers_count\"]].head())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65b348cc",
      "metadata": {},
      "source": [
        "#### Save hasil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "916e87c9",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Data berhasil dibersihkan & disimpan ke: E:/$7th/TA/Eksploring_TF-IDF/DATA/Cleaned_Text.csv\n"
          ]
        }
      ],
      "source": [
        "output_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/Cleaned_Text.csv'\n",
        "df.to_csv(output_path, index=False)\n",
        "print(\"✅ Data berhasil dibersihkan & disimpan ke:\", output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b8f3a0b3",
      "metadata": {},
      "source": [
        "## Making New Master DataFrame\n",
        "Ini buat nambahin kolom image_path ke csv. Isi image_path adalah path local dari gambar tujuannya biar mudah train_split_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74095220",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Memulai Proses Pembuatan DataFrame Master ---\n",
            "Dataset teks berhasil dimuat. Jumlah baris awal: 16305\n",
            "Menambahkan path gambar ke DataFrame...\n",
            "Memverifikasi keberadaan file gambar...\n",
            "✅ Semua baris memiliki file gambar yang sesuai.\n",
            "\n",
            "DataFrame Master berhasil disimpan di: E:/$7th/TA/Eksploring_TF-IDF/DATA/DataFrame_Master.csv\n",
            "--- Proses Selesai ---\n"
          ]
        }
      ],
      "source": [
        "# ===== MEMBUAT DATAFRAME MASTER =====\n",
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "\n",
        "def create_and_save_master_dataframe(csv_path, img_dir, output_path):\n",
        "    \"\"\"\n",
        "    Menggabungkan data teks dari CSV dengan path file gambar, memverifikasi\n",
        "    keberadaan gambar, dan menyimpan hasilnya ke file CSV baru.\n",
        "    \n",
        "    Args:\n",
        "        csv_path (str): Path ke file CSV berisi data teks.\n",
        "        img_dir (str): Path ke folder berisi file gambar.\n",
        "        output_path (str): Path untuk menyimpan DataFrame master.\n",
        "        \n",
        "    Returns:\n",
        "        pd.DataFrame: DataFrame master yang telah dibuat.\n",
        "    \"\"\"\n",
        "    print(\"--- Memulai Proses Pembuatan DataFrame Master ---\")\n",
        "    \n",
        "    # 1. Muat DataFrame Teks\n",
        "    try:\n",
        "        df = pd.read_csv(csv_path, index_col=0)\n",
        "        print(f\"Dataset teks berhasil dimuat. Jumlah baris awal: {len(df)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: File tidak ditemukan di '{csv_path}'. Proses dihentikan.\")\n",
        "        return None\n",
        "\n",
        "    # 2. Buat Kolom Path Gambar\n",
        "    print(\"Menambahkan path gambar ke DataFrame...\")\n",
        "    df['image_path'] = df.index.to_series().apply(lambda idx: os.path.join(img_dir, f\"{idx}.jpg\"))\n",
        "\n",
        "    # 3. Verifikasi Keberadaan File Gambar\n",
        "    print(\"Memverifikasi keberadaan file gambar...\")\n",
        "    df['image_exists'] = df['image_path'].apply(os.path.exists)\n",
        "    missing_images_count = (df['image_exists'] == False).sum()\n",
        "\n",
        "    if missing_images_count > 0:\n",
        "        print(f\"/nPERINGATAN: Ditemukan {missing_images_count} baris yang tidak memiliki file gambar.\")\n",
        "        df = df[df['image_exists'] == True].copy() # Filter dan buat salinan\n",
        "        print(f\"Baris tanpa gambar telah dihapus. Jumlah baris sekarang: {len(df)}\")\n",
        "    else:\n",
        "        print(\"✅ Semua baris memiliki file gambar yang sesuai.\")\n",
        "\n",
        "    # Hapus kolom verifikasi karena sudah tidak diperlukan\n",
        "    df = df.drop(columns=['image_exists'])\n",
        "\n",
        "    # 4. Simpan DataFrame Master\n",
        "    try:\n",
        "        df.to_csv(output_path, index=True) # index=True untuk menyimpan index unik\n",
        "        print(f\"/nDataFrame Master berhasil disimpan di: {output_path}\")\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR: Gagal menyimpan file. Error: {e}\")\n",
        "        return None\n",
        "        \n",
        "    print(\"--- Proses Selesai ---\")\n",
        "    return df\n",
        "\n",
        "# --- Jalankan Fungsi ---\n",
        "csv_input_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/Cleaned_Text.csv'\n",
        "image_input_dir = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/image_url'\n",
        "master_output_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/DataFrame_Master.csv'\n",
        "\n",
        "master_df = create_and_save_master_dataframe(csv_input_path, image_input_dir, master_output_path)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "24f6c612",
      "metadata": {},
      "source": [
        "#### Split Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "10989295",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "--- Memulai Proses Split Data ---\n",
            "DataFrame Master berhasil dimuat. Total baris: 16305\n",
            "Melakukan split data (80% train, 20% test)...\n",
            "\n",
            "========================================\n",
            "      PROSES SPLIT DATA SELESAI\n",
            "========================================\n",
            "\n",
            "Ukuran Data Latih (Train): (13044, 5)\n",
            "Ukuran Data Uji (Test): (3261, 5)\n",
            "\n",
            "Distribusi Label pada Data Latih (proporsi):\n",
            "Label\n",
            "0    0.699632\n",
            "1    0.300368\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "Distribusi Label pada Data Uji (proporsi):\n",
            "Label\n",
            "0    0.699479\n",
            "1    0.300521\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "--- Proses Selesai ---\n",
            "\n",
            "Contoh 5 baris pertama dari Data Latih (train_df):\n",
            "                                              full_text  /\n",
            "9856  @Franken_blues George Soros yg jahat banget ba...   \n",
            "7567  pergerakan IHSG 3 hari terakhir dibuka down me...   \n",
            "727   Ramadan penuh berkah saatnya nonton Shopee Liv...   \n",
            "4934  Rupiah menguat gaes... . . . . . . . . . . . ....   \n",
            "9659  Penutupan sesi 2 Jumat 13 Juni 2025 IHSG 7 166...   \n",
            "\n",
            "                                             clean_text  image_corelation  /\n",
            "9856  george soros jahat banget merah untung hancur ...                 0   \n",
            "7567  gera ihsg 3 buka down tengah rebound akhir cen...                 0   \n",
            "727   ramadan penuh berkah tonton shopee live untung...                 1   \n",
            "4934                           rupiah kuat gaes ringgit                 1   \n",
            "9659      tutup sesi 2 jumat 13 2025 ihsg 7 166 06 0 53                 1   \n",
            "\n",
            "      Label                                         image_path  \n",
            "9856      0  E:/$7th/TA/Eksploring_TF-IDF/DATA/image_url/98...  \n",
            "7567      0  E:/$7th/TA/Eksploring_TF-IDF/DATA/image_url/75...  \n",
            "727       0  E:/$7th/TA/Eksploring_TF-IDF/DATA/image_url/72...  \n",
            "4934      1  E:/$7th/TA/Eksploring_TF-IDF/DATA/image_url/49...  \n",
            "9659      0  E:/$7th/TA/Eksploring_TF-IDF/DATA/image_url/96...  \n"
          ]
        }
      ],
      "source": [
        "# ===== CELL 2: SPLIT DATA LATIH DAN DATA UJI =====\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def split_data(master_df_path):\n",
        "    \"\"\"\n",
        "    Memuat DataFrame master dan membaginya menjadi set data latih dan uji.\n",
        "    \n",
        "    Args:\n",
        "        master_df_path (str): Path ke file DataFrame_Master.csv.\n",
        "        \n",
        "    Returns:\n",
        "        tuple: Berisi (train_df, test_df).\n",
        "    \"\"\"\n",
        "    print(\"/n--- Memulai Proses Split Data ---\")\n",
        "    \n",
        "    # 1. Muat DataFrame Master\n",
        "    try:\n",
        "        df = pd.read_csv(master_df_path, index_col=0)\n",
        "        print(f\"DataFrame Master berhasil dimuat. Total baris: {len(df)}\")\n",
        "    except FileNotFoundError:\n",
        "        print(f\"ERROR: File tidak ditemukan di '{master_df_path}'. Pastikan Cell 1 sudah dijalankan.\")\n",
        "        return None, None\n",
        "\n",
        "    # 2. Pisahkan Fitur (X) dan Target (y)\n",
        "    X = df\n",
        "    y = df['Label']\n",
        "\n",
        "    # 3. Lakukan Split Data dengan Stratifikasi\n",
        "    print(\"Melakukan split data (80% train, 20% test)...\")\n",
        "    train_df, test_df = train_test_split(X, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "    # 4. Tampilkan Ringkasan Hasil Split\n",
        "    print(\"/n\" + \"=\"*40)\n",
        "    print(\"      PROSES SPLIT DATA SELESAI\")\n",
        "    print(\"=\"*40)\n",
        "    print(f\"/nUkuran Data Latih (Train): {train_df.shape}\")\n",
        "    print(f\"Ukuran Data Uji (Test): {test_df.shape}\")\n",
        "    print(\"/nDistribusi Label pada Data Latih (proporsi):\")\n",
        "    print(train_df['Label'].value_counts(normalize=True))\n",
        "    print(\"/nDistribusi Label pada Data Uji (proporsi):\")\n",
        "    print(test_df['Label'].value_counts(normalize=True))\n",
        "    \n",
        "    print(\"/n--- Proses Selesai ---\")\n",
        "    return train_df, test_df\n",
        "\n",
        "# --- Jalankan Fungsi ---\n",
        "master_file_path = r'/home/spil/1Bagus/BACKUP/TA/Multimodal_Process_Exploration/DATA/DataFrame_Master.csv'\n",
        "train_df, test_df = split_data(master_file_path)\n",
        "\n",
        "if train_df is not None:\n",
        "    print(\"/nContoh 5 baris pertama dari Data Latih (train_df):\")\n",
        "    print(train_df.head())"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
